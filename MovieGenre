import java.io.IOException;
import java.util.*;


import org.apache.hadoop.fs.Path;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;


public class MovieGenre {
	
	public static class Map extends Mapper<LongWritable, Text, Text, Text> {
	    private Text genre = new Text();
	    private Text movie = new Text("Genre");
	    public String movies;
	    
	    @Override
	    //get movie names from configuration
	    protected void setup(Context context) throws IOException, InterruptedException{
	    	Configuration conf = context.getConfiguration();
	    	movies = conf.get("Movies");
	    }
	        
	    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
	        //split movies to get individual movie names
	    	String[] movieList = movies.split(",");
	    	
	    	ArrayList<String> moviesList = new ArrayList<String>();
	    	//add to movies to ArrayList
	    	for(int i=0; i<movieList.length; i++){
	    		moviesList.add(movieList[i]);
	    	}
	    	//tokenize input from movies.dat
	    	String[] lineTokens = value.toString().split("::");
	        
	        for(String movieName : moviesList){
	        	if(lineTokens[1] != null && lineTokens[1].length() != 0 && lineTokens[1].startsWith(movieName)){
	        		genre = new Text(lineTokens[2]);
	        		context.write(movie, genre);
	        	}
	        }
	    }
	 }
	
	public static class Reduce extends Reducer<Text, Text, Text, Text> {

	    public void reduce(Text key, Iterable<Text> values, Context context) 
	      throws IOException, InterruptedException {
	        
	    	String output = "";
	        HashMap<String, String> genres = new HashMap<String, String>();
	    	//iterate through list of genres
	    	for(Text val : values){
	    		String[] genreList = val.toString().split("\\|");
	    		for(int j=0; j<genreList.length; j++){
	    			//add genres to HashMap discarding duplicate genres
	    			genres.put(genreList[j], genreList[j]);
	    		}
	    	}
	        
	    	int size = genres.size();
	    	int count = 0;
	    	for (String genre : genres.values()) {
	    		//if last genre in HashMap don't append ',' afterwards
	    		if(count == (size-1)){
	    			output = output.concat(genre);
	    			break;
	    		}
	    		//concat genre to output with ', '
	    		else{
	    			output = output.concat(genre+", ");
	    			count++;
	    		}
	    	}
	    	
	        context.write(key, new Text(output));
	     }
	 }
	        
	 public static void main(String[] args) throws Exception {
		 
	    Configuration conf = new Configuration();        
	    
	    //send arguments(movie names) to mapper
	    try{
	    	if(args[2] != null && !args[2].isEmpty()){
	    		String movies = args[2];
	    		conf.set("Movies", movies);
	    	}
	    }
	    
	    //handle missing arguments
	    catch(ArrayIndexOutOfBoundsException exc){
	    	conf.set("Movies", "none");
	    }
	    
	    Job job = new Job(conf, "MovieGenre");
	    
	    job.setOutputKeyClass(Text.class);
	    job.setOutputValueClass(Text.class);
	    job.setJarByClass(MovieGenre.class);
	    job.setMapperClass(Map.class);
	    //job.setCombinerClass(Reduce.class);
	    job.setReducerClass(Reduce.class);
	    
	    job.setInputFormatClass(TextInputFormat.class);
	    job.setOutputFormatClass(TextOutputFormat.class);
	        
	    FileInputFormat.addInputPath(job, new Path(args[0]));
	    FileOutputFormat.setOutputPath(job, new Path(args[1]));
	    
	    job.waitForCompletion(true);
	 }
}
